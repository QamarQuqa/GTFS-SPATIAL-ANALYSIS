{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-size:30px ;font-weight: bold; line-height: 40px;\"> Read GTFS-R files<p/>\n",
    "<p style=\"text-align:center;  line-height: 0px;font-weight: bold;\"> Nov 3, 2021<p/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>This notebook will read JSON files and store them in data frames. The idea here is to read a subset of files then store them in a CSV files then clear memory in order to continue reading the remaining files. Finally, will combine all subset csv files into one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd  # data processing\n",
    "import numpy as np  # linear algebra\n",
    "import glob  # find files recursively\n",
    "import re\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"gtfs19\"\n",
    "#we shall store all the file names in this list\n",
    "filelist = []\n",
    "\n",
    "V_INFO = []\n",
    "\n",
    "x = 0 \n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        #append the file name to the list\n",
    "        filelist.append(os.path.join(root,file))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_df(df,c):\n",
    "    appended_data =pd.DataFrame()\n",
    "    appended_data=appended_data.append(df,ignore_index=True)\n",
    "    name = \"df\" + str(c) + \".csv\"\n",
    "    appended_data.to_csv(name, index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "\n",
    "def readjsonObject(f,x,c):\n",
    "\n",
    "    for jsonObj in f:\n",
    "        V_DICT = json.loads(jsonObj)\n",
    "        V_INFO.append(V_DICT)\n",
    "        \n",
    "        #if num of files == 300 then create df \n",
    "        if x == 300:\n",
    "            lista = store_info(V_INFO)\n",
    "            df = json_as_df(lista)\n",
    "            appended_data = append_df(df,c)\n",
    "            \n",
    "            V_INFO.clear()\n",
    "            time.sleep(1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "c=0\n",
    "for name in filelist:\n",
    "    with open(name) as f:\n",
    "        #for jsonObj in f:\n",
    "        #    V_DICT = json.loads(jsonObj)\n",
    "        #    V_INFO.append(V_DICT)\n",
    "        x = x+1\n",
    "        readjsonObject(f,x,c)\n",
    "        if x == 300:\n",
    "            x = 0\n",
    "            c = c+1\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def store_info(V_INFO):\n",
    "    lista = []\n",
    "    x = 0\n",
    "\n",
    "    for V in V_INFO :\n",
    "        for i in V[\"Entities\"]:\n",
    "\n",
    "            try:\n",
    "\n",
    "\n",
    "                TripId =  i[\"Vehicle\"][\"Trip\"][\"TripId\"]\n",
    "                RouteId =  i[\"Vehicle\"][\"Trip\"][\"RouteId\"] \n",
    "                Trip_StartTime =  i[\"Vehicle\"][\"Trip\"][\"StartTime\"]\n",
    "                Trip_StartDate =  i[\"Vehicle\"][\"Trip\"][\"StartDate\"]\n",
    "                schedule_relationship =  i[\"Vehicle\"][\"Trip\"][\"schedule_relationship\"]\n",
    "\n",
    "                V_ID =  i[\"Vehicle\"][\"Vehicle\"][\"Id\"] \n",
    "\n",
    "                VP_Latitude =  i[\"Vehicle\"][\"Position\"][\"Latitude\"]  \n",
    "                VP_Longitude =  i[\"Vehicle\"][\"Position\"][\"Longitude\"] \n",
    "                VP_Bearing =  i[\"Vehicle\"][\"Position\"][\"Bearing\"] \n",
    "                VP_Speed =  i[\"Vehicle\"][\"Position\"][\"Speed\"] \n",
    "\n",
    "                V_Timestamp =  i[\"Vehicle\"][\"Timestamp\"]\n",
    "                V_occupancy_status =  i[\"Vehicle\"][\"occupancy_status\"]\n",
    "\n",
    "\n",
    "\n",
    "                app = {\n",
    "\n",
    "                     \"TripId\" : TripId,\n",
    "                     \"RouteId\" : RouteId,\n",
    "                     \"Trip_StartTime\" : Trip_StartTime,\n",
    "                     \"Trip_StartDate\" : Trip_StartDate,\n",
    "                     \"schedule_relationship\"  : schedule_relationship,\n",
    "\n",
    "                     \"V_ID\" : V_ID,\n",
    "\n",
    "                     \"VP_Latitude\" : VP_Latitude,\n",
    "                     \"VP_Longitude\" : VP_Longitude,\n",
    "                     \"VP_Bearing\" : VP_Bearing,\n",
    "                     \"VP_Speed\" : VP_Speed,\n",
    "\n",
    "                     \"V_Timestamp\" : V_Timestamp,\n",
    "                     \"V_occupancy_status\" : V_occupancy_status\n",
    "\n",
    "                    }\n",
    "\n",
    "                lista.append(app)\n",
    "\n",
    "            except:\n",
    "                None\n",
    "\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_as_df(lista):\n",
    "    with open('filename.json', 'w') as outfile:\n",
    "        json.dump(lista, outfile)\n",
    "\n",
    "    with open('filename.json') as table:\n",
    "        data = json.load(table) \n",
    "    df = pd.DataFrame(data,columns=['V_ID', 'TripId','RouteId','Trip_StartTime',\n",
    "                                    'Trip_StartDate', 'schedule_relationship',\n",
    "                                    'VP_Latitude', 'VP_Longitude', 'VP_Bearing', \n",
    "                                    'VP_Speed','V_Timestamp', 'V_occupancy_status']) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Here, will create one dataframe that merge all subset csv files in one data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd  # data processing\n",
    "import numpy as np  # linear algebra\n",
    "import glob  # find files recursively\n",
    "import re\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "path = r'GTFSR-CSV-FILES' \n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_csv('FINAL_DATA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
